raster::stack("./dat/Cydia.pomonella.grd")
hold <- raster::stack("./dat/Cydia.pomonella.grd")
hold
names(hold)
last(names(hold))
sub('.', '', last(names(hold)))
as.Date(sub('.', '', last(names(hold)))
)
str_replace_all(sub('.', '', last(names(hold))), ".", "-")
str_replace_all(sub('.', '', last(names(hold))), "/.", "-")
str_replace_all(sub('.', '', last(names(hold))), "[/.]", "-")
as.Date(str_replace_all(sub('.', '', last(names(hold))), "[/.]", "-"))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("~/Buckley_Lab/Insect-Phenology-Forecaster")
runApp()
runApp()
runApp()
runApp()
library(readr)
availablePhenoSpecies <- read_csv("dat/availablePhenoSpecies.csv")
View(availablePhenoSpecies)
availableSpecies = read_rds("./dat/availablePhenoSpecies.csv")
View(availableSpecies)
View(availableSpecies)
runApp()
setwd("~/Buckley_Lab/Insect-Phenology-Forecaster")
runApp()
?writeRaster
#--This function checks the age of the phenology maps for species we have and updates them if they are over a week old.
#----availableSpecies: an optional list of species names and locations of phenology grids for corresponding species, it defaults to reading the current availablePhenoSpecies list.
updatePhenology <- function(availableSpecies = read_rds("./dat/availablePhenoSpecies.csv")){
lapply(seq_along(availableSpecies), function(i){
#Get name and filePath values from availableSpecies list at index i
name <- names(availableSpecies)[[i]]
filePath <- availableSpecies[[i]]
#Calculate file age (in days) after fetching the last date it was modified
last_update <- as.Date(file.info(availableSpecies[[i]])$mtime)
file_age <- as.double.difftime(Sys.Date() - last_update)
thisYear <- format(Sys.Date(), '%Y')
#If the file is from the previous year and we have gridMET data from this year, delete the file and start a new one.
if(!(format(last_update, '%Y') == thisYear) && (Sys.Date() -2 >= as.Date(str_c(thisYear, "-01-01")))){
print(str_c("Creating a new phenology record for ", name, " in ", thisYear))
accumulateDD(as.Date(str_c(thisYear, "-01-01")),
Sys.Date() - 2,
species = name)
}else{
#If the file is at least a week old and we have gridMET data for this year, update it
if((file_age >= 7) && (Sys.Date() -2 >= as.Date(str_c(thisYear, "-01-01")))){
print(str_c("Updating ", name))
toUpdate <- raster::stack(availableSpecies[[i]])
accumulateDD(end_date = Sys.Date() - 2,
species = name,
cum_DD = toUpdate)
return(str_c(name, " was ", file_age, " days old. It is now 2 days old, due to gridMET restrictions."))
} else return(str_c(name, " was updated less than a week ago (", file_age, " days). It will be updated in ", (7 - file_age), " days."))
}})}
#--Note: degree.days.mat(tmin, tmax, BDT) must be declared prior to execution
#Optional arguments:
# Note: BDT and EADDC arguments must be specified if species is not specified
#       - start_date: a date to begin accumulation at
#       - end_date: a date to stop accumulation at (default: two days ago)
#       - BDT: either an integer BDT value or a vector of values to be averaged
#       - EADDC: either an integer EADDC value or a vector of values to be averaged
#       - cum_DD: a rasterLayer containing cumulative Degree Day values on the start date
#                 (Degree days will begin accumulating from here, otherwise they start at 0)
#       - species: a string species name that will be queried to get mean BDT and EADDC values from ./dat/AppendixS3_SeasonalityDatabase.csv
accumulateDD <- function(start_date = as.Date(str_c(year(Sys.Date()), '-01-01')), end_date = Sys.Date() -2, BDT = NULL, EADDC = NULL, cum_DD = NULL, species = NULL){
#Define area of interest
print(cum_DD)
if(!is.null(cum_DD)){
print("Matching start date with layer")
start_date <- str_replace_all(sub('.', '', last(names(cum_DD))), "[/.]", "-")
}
if(!is.Date(start_date)){start_date <- as.Date(start_date)}
if(!is.Date(end_date)){end_date <- as.Date(end_date)}
print(start_date)
if((is.null(BDT) || is.null(EADDC)) && is.null(species)){return("Please provide BDT and EADDC arguments, or a species to query")}
if(!is.null(species)){
toAccumulate <- get_dfWrangled() %>% filter(Species == species)
print(str_c("Species selected: ", species))
print("BDT Values Found: ")
print(toAccumulate$BDT.C)
BDT <- mean(toAccumulate$BDT.C)
print(str_c("Average BDT: ", BDT))
print("EADDC Values Found: ")
print(toAccumulate$EADDC)
EADDC <- mean(toAccumulate$EADDC)
print(str_c("Average EADDC: ", EADDC))}
#Find means of BDT and EADDC if vector of either is passed in
if(length(BDT) > 1){
print(str_c("Averaging BDTs: ", BDT))
BDT <- mean(BDT)
print(str_c("Average BDT: ", BDT))}
if(length(EADDC) > 1){
print(str_c("Averaging EADDCs: ", EADDC))
EADDC <- mean(EADDC)
print(str_c("Average EADDC: ", EADDC))}
print(str_c("BDT: ", BDT, ", EADDC: ", EADDC))
AOI = aoi_get(state = "conus")
#Get temp raster stack for start_date
#raster::plot(AOI)
p = getGridMET(AOI, param = c('tmax','tmin'), startDate = start_date)
r = raster::stack(p$tmax, p$tmin)
names(r) = c('tmax', 'tmin')
#print("not above here")
#Initialize cum_DD to DD values for start_date
if(is.null(cum_DD)){
#print("initializing")
pastStack <- NULL
cum_DD <- calc(r, fun = function(x){
#print(value(x[2]))
degree.days.mat(value(x[2]) -273.15, value(x[1]) -273.15, BDT)})
}else{
pastStack <- cum_DD
cum_DD <- raster(pastStack, layer = nlayers(pastStack))}
print(cum_DD)
# cum_DD <- calc(r, fun = function(x){
#   degree.days.mat(x[2] / 10, x[1] / 10, BDT)})
#Set current day to the next start day
week <- 1
current_date = start_date + 1
the_stack <- NULL
#Accumulate Degree Days from current_date to end_date, inclusive.
while(current_date <= end_date){
#Get raster stack of tmin and tmax for current day
temps = getGridMET(AOI, param = c('tmax','tmin'), startDate = current_date)
tstack = raster::stack(temps$tmax, temps$tmin)
names(tstack) = c('tmax', 'tmin')
print(current_date)
#Calculate todays DD values
current_DD <- calc(tstack, fun = function(x){degree.days.mat(value(x[2]) -273.15, value(x[1]) -273.15, BDT)})
#print(identical(current_DD, cum_DD))
names(current_DD) = c(current_date)
#Add cumulative DD values to current_date DD values (current_DD)
cum_DD <- cum_DD + current_DD
#Reset cum_DD values greater than EADDC to 0
cum_DD <- calc(cum_DD, fun = function(cumul){
if (!is.na(cumul[1]) && (cumul[1] >= EADDC)){
return(as.vector(EADDC))}
else {
return(cumul[1])}})
#Increment current_date
names(cum_DD) = c(current_date)
week <- week + 1
current_date = current_date + 1
if(week == 7){
if(!is_null(pastStack)){
the_stack <- raster::stack(pastStack, cum_DD)
}else{
the_stack <- raster::stack(cum_DD)}
print(str_c("the_stack: ",the_stack))
print(names(the_stack))
}
if(week == 14){
#if(is.null(the_stack)){the_stack = raster::stack("holdraster.grd")}
the_stack <- raster::stack(the_stack, cum_DD)
#writeRaster(the_stack, "holdraster.grd", overwrite=TRUE)
print(the_stack)
print(names(the_stack))
#the_stack <- NULL
week <- 7
}
}
#Update ./dat/availablePhenoSpecies.csv and ./dat/phenoSpeciesEADDC.csv with new species entry
if(!is.null(species)){
filePath <- str_c("./dat/", make.names(species), ".grd")
availablePhenoSpecies <- read_rds("./dat/availablePhenoSpecies.csv")
if(!is.null(availablePhenoSpecies[[species]])){availablePhenoSpecies[[species]] <- NULL}
else{
speciesEADDC_Dict <- read_rds("./dat/phenoSpeciesEADDC.csv")
speciesEADDC_Dict[[filePath]] <- EADDC
write_rds(speciesEADDC_Dict, "./dat/phenoSpeciesEADDC.csv")
speciesBDT_Dict <- read_rds("./dat/phenoSpeciesBDT.csv")
speciesBDT_Dict[[filePath]] <- BDT
write_rds(speciesBDT_Dict, "./dat/phenoSpeciesBDT.csv")}
#Add species to available list
availablePhenoSpecies <- append(availablePhenoSpecies, filePath)
print(str_c("Saving species: ", species))
names(availablePhenoSpecies)[length(availablePhenoSpecies)] <- str_c(species)
write_rds(availablePhenoSpecies, "./dat/availablePhenoSpecies.csv")}
else{filePath <- str_c("./dat/", make.names(current_date), ".grd")}
#Save the raster to the dat folder
print(str_c("Writing raster: ", the_stack))
#writeRaster(x = the_stack, filename = filePath, overwrite=TRUE)
return(the_stack)
#raster::plot(newR)
}
get_dfWrangled <- function(){
#Import seasonality database
AppendixS3_SeasonalityDatabase <- read.csv("./dat/AppendixS3_SeasonalityDatabase.csv", header=TRUE)
#Selecting certain columns and creating mean_* columns
dfWrangled <-  as_tibble(AppendixS3_SeasonalityDatabase) %>%
dplyr::select(Species, Species.1, BDT.C, EADDC, lat, lon) %>%
group_by(Species.1) %>%
mutate(mean_BDT.C = mean(BDT.C, na.rm=TRUE),
mean_EADDC = mean(EADDC, na.rm=TRUE))
#Remove physiological outliers
dfWrangled = subset(dfWrangled, dfWrangled$BDT.C > -7 & dfWrangled$EADDC < 2000)
#Restrict to dat with lat / lon
dfWrangled = dfWrangled[which(!is.na(dfWrangled$lon) & !is.na(dfWrangled$lat) ),]
dfWrangled$uid <- seq.int(nrow(dfWrangled))
return(dfWrangled)}
#--This function checks the age of the phenology maps for species we have and updates them if they are over a week old.
#----availableSpecies: an optional list of species names and locations of phenology grids for corresponding species, it defaults to reading the current availablePhenoSpecies list.
updatePhenology <- function(availableSpecies = read_rds("./dat/availablePhenoSpecies.csv")){
lapply(seq_along(availableSpecies), function(i){
#Get name and filePath values from availableSpecies list at index i
name <- names(availableSpecies)[[i]]
filePath <- availableSpecies[[i]]
#Calculate file age (in days) after fetching the last date it was modified
last_update <- as.Date(file.info(availableSpecies[[i]])$mtime)
file_age <- as.double.difftime(Sys.Date() - last_update)
thisYear <- format(Sys.Date(), '%Y')
#If the file is from the previous year and we have gridMET data from this year, delete the file and start a new one.
if(!(format(last_update, '%Y') == thisYear) && (Sys.Date() -2 >= as.Date(str_c(thisYear, "-01-01")))){
print(str_c("Creating a new phenology record for ", name, " in ", thisYear))
accumulateDD(as.Date(str_c(thisYear, "-01-01")),
Sys.Date() - 2,
species = name)
}else{
#If the file is at least a week old and we have gridMET data for this year, update it
if((file_age >= 7) && (Sys.Date() -2 >= as.Date(str_c(thisYear, "-01-01")))){
print(str_c("Updating ", name))
toUpdate <- raster::stack(availableSpecies[[i]])
return(accumulateDD(end_date = Sys.Date() - 2,
species = name,
cum_DD = toUpdate))
#return(str_c(name, " was ", file_age, " days old. It is now 2 days old, due to gridMET restrictions."))
} else return(str_c(name, " was updated less than a week ago (", file_age, " days). It will be updated in ", (7 - file_age), " days."))
}})}
pomoGrid <- updatePhenology()
#DEGREE DAYS CALCULATION
#Single sine wave approximation from Baskerville & Emin 1969
#(see http://www.ipm.ucdavis.edu/WEATHER/ddss_tbl.html)
#Input:
#Tdat: 2 column matrix with Tmin followed by Tmax
#LDT:lower developmental threshold
#------Adapted from Lauren Buckley (no longer allows for negative DDs and accepts NA values)
degree.days.mat=function(Tmin, Tmax, LDT){
# entirely above LDT
#|| is.null(Tmin) || is.null(Tmax)
if(is.na(Tmin) || is.na(Tmax) || is.na(Tmin) || is.na(Tmax)){dd = NA}
else{
if(Tmin>=LDT) {dd = (Tmax+Tmin)/2-LDT}
# intercepted by LDT
## for single sine wave approximation
if(Tmin<LDT && Tmax>LDT){
alpha=(Tmax-Tmin)/2
theta1=asin(((LDT-(Tmax+Tmin))/alpha)*pi/180)
dd=1/pi*(((Tmax+Tmin)/2-LDT)*(pi/2-theta1)+alpha*cos(theta1))
if(!is.na(dd))if(dd<0){dd=0}
} #matches online calculation
# entirely below LDT
if(Tmax <= LDT){dd = 0}}
return(dd)
}
pomoGrid <- updatePhenology()
pomoGrid
pomoGrid[[7]]
pomoGrid <- pomoGrid[[7]]
pomoGrid
species <- "Cydia pomonella"
filePath <- str_c("./dat/", make.names(species), ".grd")
writeRaster(pomoGrid, filePath, overwrite=TRUE)
writeRaster(pomoGrid, filePath, overwrite=TRUE)
writeRaster(pomoGrid, filePath, overwrite=TRUE)
writeRaster(pomoGrid, filePath)
writeRaster(pomoGrid, filePath, overwrite=TRUE)
saveRDS(pomoGrid, filePath)
readRDS("./dat/Cydia.pomonella.grd")
tester <- readRDS("./dat/Cydia.pomonella.grd")
raster::stack("./dat/Cydia.pomonella.grd")
warnings
raster::stack(tester)
tester
runApp()
runApp()
lifesaver <- readRDS("./dat/AvailablePhenoSpecies.csv")
View(lifesaver)
list("Cydia pomonella" = "./dat/Cydia.pomonella.grd")
tempAvailableSpecies <- list("Cydia pomonella" = "./dat/Cydia.pomonella.grd")
View(tempAvailableSpecies)
saveRDS(tempAvailableSpecies, "./dat/AvailablePhenoSpecies.csv")
readRDS("./dat/AvailablePhenoSpecies.csv")
runApp()
runApp()
raster::stack("./dat/Cydia.pomonella.grd")
larry <- raster::stack("./dat/Cydia.pomonella.grd")
larry
saveRDS(larry, "./dat/Cydia.pomonella.grd")
readRDS("./dat/Cydia.pomonella.grd")
runApp()
runApp()
View(lifesaver)
write_rds(lifesaver, "./dat/availablePhenoSpecies.csv")
View(availableSpecies)
availableSpecies
larry <- raster::stack("./dat/Aphis.gossypii.grd")
saveRDS(larry, "./dat/Aphis.gossypii.grd")
larry <- raster::stack("./dat/Acyrthosiphon.pisum.grd")
saveRDS(larry, "./dat/Acyrthosiphon.pisum.grd")
larry <- raster::stack("./dat/Acyrthosiphon.kondoi.grd")
saveRDS(larry, "./dat/Acyrthosiphon.kondoi.grd")
larry <- raster::stack("./dat/Agrotis.ipsilon.grd")
saveRDS(larry, "./dat/Agrotis.ipsilon.grd")
larry <- raster::stack("./dat/Drosophila.melanogaster.grd")
saveRDS(larry, "./dat/Drosophila.melanogaster.grd")
larry <- raster::stack("./dat/Trogoderma.granarium.grd")
saveRDS(larry, "./dat/Trogoderma.granarium.grd")
runApp()
runApp()
runApp()
runApp()
runApp()
View(larry)
names(larry)
runApp()
runApp()
runApp()
runApp()
}
if(interactive()) {
library(leaflet)
library(leaftime)
library(htmltools)
#Build data.frame with 10 obs + 3 cols
power <- data.frame(
"Latitude" = c(
33.515556, 38.060556, 47.903056, 49.71, 49.041667, 31.934167,
54.140586, 54.140586, 48.494444, 48.494444
),
"Longitude" = c(
129.837222, -77.789444, 7.563056, 8.415278, 9.175, -82.343889,
13.664422, 13.664422, 17.681944, 17.681944
),
"start" = seq.Date(as.Date("2015-01-01"), by = "day", length.out = 10),
"end" = seq.Date(as.Date("2015-01-01"), by = "day", length.out = 10) + 1
)
# use geojsonio to convert our data.frame
#  to GeoJSON which timeline expects
power_geo <- geojsonio::geojson_json(power,lat="Latitude",lon="Longitude")
# we can add data in addTimeline
leaflet() %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(data = power_geo)
# or we can add data in leaflet()
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline()
# we can control the slider controls through sliderOptions
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
sliderOpts = sliderOptions(
formatOutput = htmlwidgets::JS(
"function(date) {return new Date(date).toDateString()}
"),
position = "bottomright",
step = 10,
duration = 3000,
showTicks = FALSE
)
)
# we can control the timeline through timelineOptions
#  wondering what should be the default
#  currently timeline uses marker
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
timelineOpts = timelineOptions(
pointToLayer = htmlwidgets::JS(
"
function(data, latlng) {
return L.circleMarker(latlng, {
radius: 3
})
}
"
),
style = NULL
)
)
# change styling manually
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
timelineOpts = timelineOptions(
pointToLayer = htmlwidgets::JS(
"
function(data, latlng) {
return L.circleMarker(latlng, {
radius: 10,
color: 'black',
fillColor: 'pink',
fillOpacity: 1
})
}
"
),
styleOptions = NULL
)
)
# change style with styleOptions helper function
#   this will change style for all points
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
timelineOpts = timelineOptions(
styleOptions = styleOptions(
radius = 10,
color = "black",
fillColor = "pink",
fillOpacity = 1
)
)
)
# to style each point differently based on the data
power_styled <- power
# IE does not like alpha so strip colors of alpha hex
power_styled$color <- substr(topo.colors(6)[ceiling(runif(nrow(power),0,6))],1,7)
power_styled$radius <- seq_len(nrow(power_styled)) # ceiling(runif(nrow(power),3,10))
leaflet(geojsonio::geojson_json(power_styled)) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
# addCircleMarkers(
#   data = power_styled, lat = ~Latitude, lng = ~Longitude, radius = 11
# ) %>%
addTimeline(
timelineOpts = timelineOptions(
styleOptions = NULL, # make sure default style does not override
pointToLayer = htmlwidgets::JS(
"
function(data, latlng) {
return L.circleMarker(
latlng,
{
radius: +data.properties.radius,
color: data.properties.color,
fillColor: data.properties.color,
fillOpacity: 1
}
);
}
"
)
)
)
# we can use onchange to handle timeline change event
leaflet(power_geo) %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
onchange = htmlwidgets::JS("function(e) {console.log(e, arguments)}")
)
leaflet(power_geo, elementId = "leaflet-wide-timeline") %>%
addTiles() %>%
setView(44.0665,23.74667,2) %>%
addTimeline(
width = "96%"
)
}
install.packages("leaftime")
library(leaflet)
library(leaftime)
?interactive
library(leaflet)
library(leaftime)
library(htmltools)
#Build data.frame with 10 obs + 3 cols
power <- data.frame(
"Latitude" = c(
33.515556, 38.060556, 47.903056, 49.71, 49.041667, 31.934167,
54.140586, 54.140586, 48.494444, 48.494444
),
"Longitude" = c(
129.837222, -77.789444, 7.563056, 8.415278, 9.175, -82.343889,
13.664422, 13.664422, 17.681944, 17.681944
),
"start" = seq.Date(as.Date("2015-01-01"), by = "day", length.out = 10),
"end" = seq.Date(as.Date("2015-01-01"), by = "day", length.out = 10) + 1
)
power
# use geojsonio to convert our data.frame
#  to GeoJSON which timeline expects
power_geo <- geojsonio::geojson_json(power,lat="Latitude",lon="Longitude")
runApp()
runApp()
runApp()
?addRasterImage
runApp()
?addProviderTiles
runApp()
runApp()
names(providers)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
