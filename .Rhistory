r$tmin[5001]
r$tmin[50001]
for (x in 90000:90100) {
print(degree.days.mat(r$tmin[x], r$tmax[x], 10))
}
for (i in 1:nrow(r)) {
dd = degree.days.mat(r$tmin[i], r$tmax[i], 15)
r$dd[i] <- dd
}
for (i in 1:nrow(shortr)) {
dd = degree.days.mat(r$tmin[i], r$tmax[i], 15)
r$dd[i] <- dd
}
r$tmin[90000]
for (i in 90000:90100) {
dd = degree.days.mat(r$tmin[i], r$tmax[i], 15)
r$dd[i] <- dd
}
r$dd <- NA
for (i in 90000:90100) {
dd = degree.days.mat(r$tmin[i], r$tmax[i], 15.0)
r$dd[i] <- dd
}
View(r)
# a = raster(r)
rasterVis::levelplot(r)
r$tmin[i] / 10
for (i in 90000:90100) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
# a = raster(r)
rasterVis::levelplot(r)
nrow(r)
for (i in r) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
for (r$dd in r) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
compr <- calc(r, function(x){degree.days.mat(x$tmax, x$tmin, 15)})
compr <- calc(r, function(x){degree.days.mat(x[1], x[2], 15)})
head(r)
print(head(dd))
print(head(r))
head(shortr)
shortr <- na.omit(r)
View(shortr)
shortr <- na.omit(r$dd)
shortr <- na.omit(r$tmax)
shortr2 <- na.omit(shortr$tmin)
View(shortr)
?na.omit
r = raster::stack(p$tmax, p$tmin)
names(r) = c('tmax', 'tmin')
comp = calc(r, degree.days.raster)
r <- na.omit(r)
r$dd <- NA
for (i in 1:nrows(r)) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
for (i in 1:nrow(r)) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
r$tmin
for (i in 1:nrow(r$tmin)) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
for (i in 1:nrow(r$tmax)) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
for (i in 1:ncell(r$tmax)) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
glimpse(r)
for (i in 1:r@nrows) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
for (i in 1:r@nrows) {
dd = degree.days.mat(r$tmin[i,1] / 10, r$tmax[i,1] / 10, 15.0)
r$dd[i] <- dd
}
dd = degree.days.mat(r$tmin[1,i] / 10, r$tmax[1,i] / 10, 15.0)
for (i in r@nrows) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, 15.0)
r$dd[i] <- dd
}
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, "15.0")
for (i in 1:r@nrows) {
dd = degree.days.mat(r$tmin[i] / 10, r$tmax[i] / 10, "15.0")
r$dd[i] <- dd
}
setMinMax(r$tmax)
setMinMax(r$tmin)
r$crs
r@crs
list(268:316)
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
[268:316]
[268,316]
vec <- [268:316]
vec <- [268,316]
vec <- as.vector(268:316)
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
?colorNumeric
View(pal)
knitr::opts_chunk$set(echo = TRUE)
inputPanel(
selectInput("n_breaks", label = "Number of bins:",
choices = c(10, 20, 35, 50), selected = 20),
sliderInput("bw_adjust", label = "Bandwidth adjustment:",
min = 0.2, max = 2, value = 1, step = 0.2)
)
shiny::runApp('Buckley_Lab/Insect-Phenology-Forecaster')
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
as.Date(str_c(year(Sys.Date()), '-01-01'))
runApp('Buckley_Lab/Insect-Phenology-Forecaster')
shiny::runApp('test')
install.packages("googleway")
runApp('test')
google_keys()
runApp('test')
install.packages("googleway")
install.packages("googleway")
runApp('test')
setwd("~/test")
setwd("~/Buckley_Lab/Insect-Phenology-Forecaster")
install.packages("shinyglide")
runApp()
runApp()
runApp('~/test')
?pickerInput
get_dfWrangled <- function(){
#Import seasonality database
AppendixS3_SeasonalityDatabase <- read.csv("./dat/AppendixS3_SeasonalityDatabase.csv", header=TRUE)
#Selecting certain columns and creating mean_* columns
dfWrangled <-  as_tibble(AppendixS3_SeasonalityDatabase) %>%
dplyr::select(Species, Species.1, BDT.C, EADDC, lat, lon) %>%
group_by(Species.1) %>%
mutate(mean_BDT.C = mean(BDT.C, na.rm=TRUE),
mean_EADDC = mean(EADDC, na.rm=TRUE))
#Remove physiological outliers
dfWrangled = subset(dfWrangled, dfWrangled$BDT.C > -7 & dfWrangled$EADDC < 2000)
#Restrict to dat with lat / lon
dfWrangled = dfWrangled[which(!is.na(dfWrangled$lon) & !is.na(dfWrangled$lat) ),]
dfWrangled$uid <- seq.int(nrow(dfWrangled))
return(dfWrangled)}
dfWrangled <- get_dfWrangled()
#Create necessary datarframe for RNOAA query
latLonDF <- dplyr::select(dfWrangled, c("Species.1", "uid", "lat", "lon"))
colnames(latLonDF) <- c("Species.1", "id", "latitude", "longitude")
#Shorten database for ease
num_spec = 65
latLonDF <- head(latLonDF, num_spec)
#Turn each row to a dataframe
pLatLonDF <- latLonDF %>%
rowwise %>%
do( X = as_tibble(.) ) %>%
ungroup
#---------------Only run the following if you want to update ghcnd-stations.txt------------
#This will query NOAA for the most up to date info on weather stations in the GHCND network
#The output is saved to a file called ghcnd-stations-current.csv, in the current working directory
updateGHCNDStations <- function(){
print("Getting ghcnd-stations.txt from NOAA...")
stationsDailyRaw <- read.fwf(url("https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt"),
widths = c(11, 9, 11, 7, 2, 31, 5, 10),
header = FALSE, strip.white = TRUE, comment.char = "",
stringsAsFactors = FALSE)
print("Getting ghcnd-inventory.txt from NOAA...")
inventoryDailyRaw <- read.fwf(url("https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-inventory.txt"),
widths = c(11, 9, 10, 5, 5, 5),
header = FALSE, strip.white = TRUE, comment.char = "",
stringsAsFactors = FALSE)
stationColNames <- c("id","latitude", "longitude", "elevation",
"state", "name", "gsn_flag", "wmo_id")
inventoryColNames <- c("id","latitude", "longitude",
"element", "first_year", "last_year")
ghcndStationsDaily <- stats::setNames(stationsDailyRaw, stationColNames)
ghcndInventoryDaily <- stats::setNames(inventoryDailyRaw, inventoryColNames)
ghcndStationsDailyComplete <- merge(ghcndStationsDaily, ghcndInventoryDaily[, -c(2, 3)], by = "id")
sturdyGHCNDStations <- tibble::as_tibble(ghcndStationsDailyComplete[stats::complete.cases(ghcndStationsDailyComplete), ])
saveRDS(sturdyGHCNDStations, file = "./dat/ghcnd-stations-current.csv")
return(sturdyGHCNDStations)}
#read in current local copy of ghcnd stations
localGHCNDStations <- readRDS(file = "./dat/ghcnd-stations-current.csv")
#Takes in a dataframe containing c("Species.1", "id", "latitude", "longitude") and returns info about nearest weather station
nearestStat <- function(Y) {meteo_nearby_stations(lat_lon_df = Y,
station_data = localGHCNDStations,
var = c("TMAX", "TMIN"),
year_min = 2000,
year_max = 2020,
radius = 500,
limit = 2
)}
#Take every dataframe in pLatLonDF and add a result column containing the RNOAA-station-id of the nearest weather station
stationLatLonDf <- pLatLonDF %>%
mutate(result = map(X, nearestStat)) %>%
unnest(cols = c(X, result)) %>%
dplyr::select("Species.1", "id", "result") %>%
rename(uid = id) %>%
unnest(cols = c(result)) %>%
rename(sid = id) %>%
dplyr::select("uid", "sid")
stationLatLonDf$rank <- rep(c(1,2), length.out = nrow(stationLatLonDf))
stationLatLonDf <- spread(stationLatLonDf, rank, sid)
colnames(stationLatLonDf) <- c("uid", "sid1", "sid2")
#Merge weather dataframe with species dataframe
speciesStationDF <- merge(x = dfWrangled, y = stationLatLonDf, by = "uid")
#Removes observations with no nearby weather stations (<500 miles) as defined by radius argument in nearestStat
speciesStationDF <- speciesStationDF[!(is.na(speciesStationDF$sid1) || speciesStationDF$sid1==""), ]
#DEGREE DAYS CALCULATION
#Single sine wave approximation from Baskerville & Emin 1969
#(see http://www.ipm.ucdavis.edu/WEATHER/ddss_tbl.html)
#Input:
#Tdat: 2 column matrix with Tmin followed by Tmax
#LDT:lower developmental threshold
#------Adapted from Lauren Buckley (no longer allows for negative DDs and accepts NA values)
degree.days.mat=function(Tmin, Tmax, LDT){
# entirely above LDT
#|| is.null(Tmin) || is.null(Tmax)
if(is.na(Tmin) || is.na(Tmax) || is.na(Tmin) || is.na(Tmax)){dd = NA}
else{
if(Tmin>=LDT) {dd = (Tmax+Tmin)/2-LDT}
# intercepted by LDT
## for single sine wave approximation
if(Tmin<LDT && Tmax>LDT){
alpha=(Tmax-Tmin)/2
theta1=asin(((LDT-(Tmax+Tmin))/alpha)*pi/180)
dd=1/pi*(((Tmax+Tmin)/2-LDT)*(pi/2-theta1)+alpha*cos(theta1))
if(!is.na(dd))if(dd<0){dd=0}
} #matches online calculation
# entirely below LDT
if(Tmax <= LDT){dd = 0}}
return(dd)
}
# cumsum with reset adapted from @jgilfillan on github, many thanks!
cumsum_with_reset <- function(x, threshold) {
cumsum <- 0
group <- 1
result <- numeric()
for (i in 1:length(x)) {
if (cumsum == threshold){
group <- group + 1
cumsum <- 0
}
cumsum <- cumsum + x[i]
if (cumsum > threshold) {
cumsum <- threshold
}
result = c(result, cumsum)
}
return (result)
}
#-----Graphing Helper Functions---------
dd_plot <- function(tMax1, tMax2,
tMin1, tMin2,
BDT, EADDC,
startTime, endTime = Sys.Date(),
species,
lat, lon,
breaks = NULL,
dateformat='%m/%y') {
UseMethod("dd_plot")
}
dd_plot.default <- function(tMax1, tMax2, tMin1, tMin2, BDT, EADDC, startTime, endTime, species, lat, lon, breaks = NULL, dateformat='%m/%y') {
#Making a new dataframe that has all of tMax1 and tMax2 for missing dates
if(!is.null(tMax1) && !is.null(tMax2) && !is.null(tMin1) && !is.null(tMin2)) {
dfTMAX <- rbind(tMax1, tMax2[!tMax2$date %in% tMax1$date,])
dfTMIN <- rbind(tMin1, tMin2[!tMin2$date %in% tMin1$date,])
} else {
# dfTMAX <- rbind(tMax1, tMax2)
# dfTMIN <- rbind(tMin1, tMin2)
if(!is.null(tMax1) && !is.null(tMin1)){
dfTMAX <- tMax1
dfTMIN <- tMin1
}else{
dfTMAX <- tMax2
dfTMIN <- tMin2
}
}
#Cleaning up dates
dfTMAX$date <- ymd(sub('T00:00:00\\.000|T00:00:00', '', as.character(dfTMAX$date)))
dfTMIN$date <- ymd(sub('T00:00:00\\.000|T00:00:00', '', as.character(dfTMIN$date)))
#Order dataframe by date
dfTMAX <- dfTMAX[order(as.Date(dfTMAX$date, format = "%y%m%d")),]
dfTMIN <- dfTMIN[order(as.Date(dfTMIN$date, format = "%y%m%d")),]
#value = NULL
#Joining TMIN and TMAX data into dfTEMP
dfTEMP <- full_join(dfTMAX, dfTMIN[ , c("date", "TMIN")], by = 'date')
#Matching units and removing errors
dfTEMP$TMAX[which(dfTEMP$TMAX==-9999)]= NA
dfTEMP$TMAX= dfTEMP$TMAX/10 #correct for tenths of degrees or mm
dfTEMP$TMIN[which(dfTEMP$TMIN==-9999)]= NA
dfTEMP$TMIN= dfTEMP$TMIN/10 #correct for tenths of degrees or mm
#Catch other NA values
dfTEMP$TMAX[which(dfTEMP$TMAX > 200)] = NA
dfTEMP$TMIN[which(dfTEMP$TMIN > 200)] = NA
dfTEMP$TMAX[which(dfTEMP$TMAX < -200)] = NA
dfTEMP$TMIN[which(dfTEMP$TMIN < -200)] = NA
dfTEMP <- na.omit(dfTEMP)
dfTEMP$dd <- NA
for (i in 1:nrow(dfTEMP)) {
dd = degree.days.mat(dfTEMP$TMIN[i], dfTEMP$TMAX[i], BDT)
dfTEMP$dd[i] <- dd
}
dDays <- dfTEMP
#Adding a csum column which sums degree days and resets after reaching threshold (EADDC)
dDays$csum <- cumsum_with_reset(dDays$dd, EADDC)
#Plot csum vs date
# plot <-  ggplot(dDays, aes(date, csum)) +
#   plot_template(df, breaks, dateformat) +
#   #ncdc_theme() +
#   geom_hline(aes(yintercept = EADDC), linetype = "dashed", color = "#ff7729", size = 1) +
#   geom_text(aes(startTime, EADDC, label = "EADDC", vjust = +1.5, hjust = -0.1), size = 4)
#------------------
observationLocationLookup <- geocode_rev(c(lat, lon))
species_locality <- str_c(observationLocationLookup$county, ", ", observationLocationLookup$state, ", ", toupper(observationLocationLookup$country_code))
#Start the plot and add the three variables to be plotted (date, csum, dd)
fig <- plot_ly(dDays, x = ~date) %>%
add_lines(y = ~csum, name = "Accumulated Degree Days") %>%
add_lines(y = ~dd, name = "Individual Degree Days", fill = 'tozeroy')
#Add generation dashed line
datesAdulthoodReached <- dDays$date[which(dDays$csum == EADDC)]
if(length(datesAdulthoodReached) != 0){
fig <- fig %>%
add_segments(x = datesAdulthoodReached +1,
xend = datesAdulthoodReached +1,
y = 0,
yend = EADDC*1.05,
name = "Eggs Reached Adulthood",
line = list(dash = "dash"))
#Add horizontal dashed line at EADDC
fig <- fig %>%
add_segments(x = startTime,
xend = endTime,
y = EADDC,
yend = EADDC,
name = "EADDC",
line = list(dash = "dash"))}
#Beautify and add date selectors
fig <- fig %>% layout(
title = str_c(species, " development in ", species_locality),
xaxis = list(
rangeselector = list(
buttons = list(
list(
count = 1,
label = "1 mo",
step = "month",
stepmode = "backward"),
list(
count = 2,
label = "6 mo",
step = "mo",
stepmode = "backward"),
list(
count = 1,
label = "YTD",
step = "year",
stepmode = "todate"))),
rangeslider = list(type = "date")),
yaxis = list(title = "Degree Days (\u00B0C)")
# annotations =
#   list(x = 1, y = -0.1, text = "Source: data I found somewhere.",
#        showarrow = F, xref='paper', yref='paper',
#        xanchor='right', yanchor='bottom', xshift=0, yshift=0,
#        font=list(size=15, color="red"))
)
#------------------
return(fig)
#scale_y_continuous(breaks = sort(c(ggplot_build(plot1)$layout$panel_ranges[[1]]$y.major_source, h)))
}
#Fetch a common name for a species or return "No available common name." if no results found
safeSci2Com <- function(df) {
com <- sci2comm(df, db = "eol", simplify = TRUE) %>%
flatten()
if(identical(com, list())){
com <- "No available common name."
} else {
#fcom <- flatten(com)
com <- com[[1]]
}
return(com)
}
glimpse(speciesStationDF)
runApp()
?searchInput
search_query <- "Acrolepiopsis assectella"
query_results <- which(speciesStationDF$Species == search_query)
query_results
query_results <- which(speciesStationDF$Species == "Poopy")
query_results
?verbatimTextOutput
runApp()
print(search_query)
query_results <- speciesStationDF[which(speciesStationDF$Species == search_query)]
query_results
speciesStationDF[1]
speciesStationDF[[1]]
speciesStationDF[[[1]]]
query_results <- which(speciesStationDF$Species == search_query)
query_results
speciesStationDF$uid[1]
speciesStationDF$uid[3]
speciesStationDF$lat[3]
speciesStationDF$lon[3]
speciesStationDF$'[3]
ok
)
;
filter(speciesStationDF, Species == search_query)
speciesStationDF %>% filter(Species == search_query) %>% select(BDT.C, EADDC, lat, lon)
query_results <- speciesStationDF %>% filter(grepl(Species, search_query, ignore.case = TRUE)) %>% select(BDT.C, EADDC, lat, lon)
query_results <- speciesStationDF %>% filter(grepl(search_query, Species, ignore.case = TRUE)) %>% select(BDT.C, EADDC, lat, lon)
query_results
search_querym <- toupper(search_query)
query_results <- speciesStationDF %>% filter(grepl(search_querym, Species, ignore.case = TRUE)) %>% select(BDT.C, EADDC, lat, lon)
query_results
lat <- query_results$lat[1]
lon <- query_results$lon[1]
observationLocationLookup <- geocode_rev(c(lat, lon))
observationLocationLookup
resultLocationLookup <- geocode_rev(c(lat, lon))
resultLocationLookup
glimpse(resultLocationLookup)
?geocode_rev
query_results <- speciesStationDF %>%
filter(grepl(search_query, Species, ignore.case = TRUE)) %>%
select(BDT.C, EADDC, lat, lon) %>%
mutate(Observation.Location = {
resultLocationLookup <- geocode_rev(c(lat, lon))
str_c(resultLocationLookup$state, ", ", toupper(resultLocationLookup$country_code))})
query_results
query_results <- speciesStationDF %>%
filter(grepl(search_query, Species, ignore.case = TRUE)) %>%
mutate(Observation.Location = {
resultLocationLookup <- geocode_rev(c(lat, lon))
str_c(resultLocationLookup$state, ", ", toupper(resultLocationLookup$country_code))}) %>%
select(BDT.C, EADDC, Observation.Location)
query_results
View(dfWrangled)
#Import seasonality database
AppendixS3_SeasonalityDatabase <- read.csv("./dat/AppendixS3_SeasonalityDatabase.csv", header=TRUE)
AppendixS3_SeasonalityDatabase
glimpse(AppendixS3_SeasonalityDatabase)
get_dfWrangled <- function(){
#Import seasonality database
AppendixS3_SeasonalityDatabase <- read.csv("./dat/AppendixS3_SeasonalityDatabase.csv", header=TRUE)
#Selecting certain columns and creating mean_* columns
dfWrangled <-  as_tibble(AppendixS3_SeasonalityDatabase) %>%
dplyr::select(Species, Species.1, BDT.C, EADDC, lat, lon, Author, Year, Journal, Location, quality) %>%
group_by(Species.1) %>%
mutate(mean_BDT.C = mean(BDT.C, na.rm=TRUE),
mean_EADDC = mean(EADDC, na.rm=TRUE))
#Remove physiological outliers
dfWrangled = subset(dfWrangled, dfWrangled$BDT.C > -7 & dfWrangled$EADDC < 2000)
#Restrict to dat with lat / lon
dfWrangled = dfWrangled[which(!is.na(dfWrangled$lon) & !is.na(dfWrangled$lat) ),]
dfWrangled$uid <- seq.int(nrow(dfWrangled))
return(dfWrangled)}
dfWrangled <- get_dfWrangled()
dfWrangled
query_results <- dfWrangled %>%
filter(grepl(search_query, Species, ignore.case = TRUE)) %>%
# mutate(Observation.Location = {
#   resultLocationLookup <- geocode_rev(c(lat, lon))
#   str_c(resultLocationLookup$state, ", ", toupper(resultLocationLookup$country_code))}) %>%
select(BDT.C, EADDC, Location)#Observation.Location)
query_results
query_results <- dfWrangled %>%
filter(grepl(search_query, Species, ignore.case = TRUE)) %>%
ungroup() %>%
# mutate(Observation.Location = {
#   resultLocationLookup <- geocode_rev(c(lat, lon))
#   str_c(resultLocationLookup$state, ", ", toupper(resultLocationLookup$country_code))}) %>%
select(BDT.C, EADDC, Location)#Observation.Location)
query_results
query_results <- dfWrangled %>%
filter(grepl(search_query, Species, ignore.case = TRUE)) %>%
ungroup() %>%
# mutate(Observation.Location = {
#   resultLocationLookup <- geocode_rev(c(lat, lon))
#   str_c(resultLocationLookup$state, ", ", toupper(resultLocationLookup$country_code))}) %>%
select(BDT.C, EADDC, Location, Journal, quality)#Observation.Location)
query_results
runApp()
runApp()
runApp()
?renderTable
runApp()
runApp()
searchSpecies
install.packages("DT")
install.packages("DT")
install.packages("DT")
output$speciesSearchResult = renderPrint({
s = input$speciesSearch_rows_selected
if(length(s)){
cat('These rows were selected: \n\n')
cat(s, sep = ', ')
}
})
